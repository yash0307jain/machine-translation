{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "5ce7e8f3-a2aa-4719-bc4d-e75c8cb9c085",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import tensorflow as tf\n",
    "\n",
    "import re\n",
    "import string\n",
    "from string import digits\n",
    "import pickle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "71bf67df-0f2d-4bd8-ba57-4676a2ed5e48",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:No training configuration found in save file, so the model was *not* compiled. Compile it manually.\n",
      "WARNING:tensorflow:No training configuration found in save file, so the model was *not* compiled. Compile it manually.\n"
     ]
    }
   ],
   "source": [
    "encoder_model = tf.keras.models.load_model(\"encoder_model\")\n",
    "decoder_model = tf.keras.models.load_model(\"decoder_model\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "7ddb3cc4-a04e-4964-ac2b-67a8ebc09d7b",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = pickle.load(open(\"pickle_data/X_train.pkl\", \"rb\"))\n",
    "y_train = pickle.load(open(\"pickle_data/y_train.pkl\", \"rb\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "76ac4193-b4ec-426b-87f3-deac174548b7",
   "metadata": {},
   "outputs": [],
   "source": [
    "max_length_src = pickle.load(open(\"pickle_data/max_length_src.pkl\", \"rb\"))\n",
    "max_length_tar = pickle.load(open(\"pickle_data/max_length_tar.pkl\", \"rb\"))\n",
    "num_decoder_tokens = pickle.load(open(\"pickle_data/num_decoder_tokens.pkl\", \"rb\"))\n",
    "input_token_index = pickle.load(open(\"pickle_data/input_token_index.pkl\", \"rb\"))\n",
    "target_token_index = pickle.load(open(\"pickle_data/target_token_index.pkl\", \"rb\"))\n",
    "reverse_target_token_index = pickle.load(open(\"pickle_data/reverse_target_token_index.pkl\", \"rb\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "1fb8058b-24e6-4cde-b822-2ebfd9591fdd",
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_batch(X = X_train, y = y_train, batch_size = 128):\n",
    "    ''' Generate a batch of data '''\n",
    "    while True:\n",
    "        for j in range(0, len(X), batch_size):\n",
    "            encoder_input_data = np.zeros((batch_size, max_length_src),dtype='float32')\n",
    "            decoder_input_data = np.zeros((batch_size, max_length_tar),dtype='float32')\n",
    "            decoder_target_data = np.zeros((batch_size, max_length_tar, num_decoder_tokens),dtype='float32')\n",
    "            for i, (input_text, target_text) in enumerate(zip(X[j:j+batch_size], y[j:j+batch_size])):\n",
    "                for t, word in enumerate(input_text.split()):\n",
    "                    encoder_input_data[i, t] = input_token_index[word] # encoder input seq\n",
    "                for t, word in enumerate(target_text.split()):\n",
    "                    if t<len(target_text.split())-1:\n",
    "                        decoder_input_data[i, t] = target_token_index[word] # decoder input seq\n",
    "                    if t>0:\n",
    "                        # decoder target sequence (one hot encoded)\n",
    "                        # does not include the START_ token\n",
    "                        # Offset by one timestep\n",
    "                        decoder_target_data[i, t - 1, target_token_index[word]] = 1.\n",
    "            yield([encoder_input_data, decoder_input_data], decoder_target_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "868dab14-a6ef-4122-9855-01474db21534",
   "metadata": {},
   "outputs": [],
   "source": [
    "def decode_sequence(input_seq):\n",
    "    # encode the input as state vectors\n",
    "    states_value = encoder_model.predict(input_seq)\n",
    "    # generate empty target sequence of length 1\n",
    "    target_seq = np.zeros((1,1))\n",
    "    # populate the first character of target sequence with the start character\n",
    "    target_seq[0,0] = target_token_index['START_']\n",
    "    \n",
    "    # sampling loop for a batch of sequence\n",
    "    # (to simplify, here we assume a batch of size 1)\n",
    "    stop_condition = False\n",
    "    decoded_sentence = ''\n",
    "    while not stop_condition:\n",
    "        output_tokens, h, c = decoder_model.predict([target_seq] + states_value)\n",
    "        \n",
    "        # sample a token\n",
    "        sampled_token_index = np.argmax(output_tokens[0, -1, :])\n",
    "        sampled_char = reverse_target_token_index[sampled_token_index]\n",
    "        decoded_sentence += ' ' + sampled_char\n",
    "        \n",
    "        # exit condition: either hit max length or find stop character\n",
    "        if (sampled_char == '_END' or len(decoded_sentence) > 50):\n",
    "            stop_condition = True\n",
    "            \n",
    "        # update the target sequence (of length 1)\n",
    "        target_seq = np.zeros((1,1))\n",
    "        target_seq[0,0] = sampled_token_index\n",
    "        \n",
    "        # update states\n",
    "        states_value = [h, c]\n",
    "        \n",
    "    return decoded_sentence"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "8e141880-283a-4f03-a397-7d71f1779925",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_gen = generate_batch(X_train, y_train, batch_size=1)\n",
    "k = -1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "cb8f41a0-d6f0-4e57-a0fa-f7efa42a125a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Input English sentence: we print geometry where we can make industrial design objects\n",
      "Actual Hindi Translation:  जहां हम औद्योगिक डिजाइन वस्तुओं को छाप सकते हैं \n",
      "Predicted Hindi Translation:  जहां हम औद्योगिक डिजाइन वस्तुओं और बिजली में सकते\n",
      "\n",
      "\n",
      "\n",
      "Input English sentence: a few oxymorons in one sentence\n",
      "Actual Hindi Translation:  और ये वाक्य विरोधाभास से भरा है। \n",
      "Predicted Hindi Translation:  और ये वाक्य वाक्य करने वाले मिलता है \n",
      "\n",
      "\n",
      "\n",
      "Input English sentence: but they would give her the broccoli if she liked the broccoli\n",
      "Actual Hindi Translation:  और गोभी देते थे अगर उसे गोभी पसंद थी। \n",
      "Predicted Hindi Translation:  और उन्हें दुकान में थे वो कंप्यूटर के बाद \n",
      "\n",
      "\n",
      "\n",
      "Input English sentence: and on top of all off these rules\n",
      "Actual Hindi Translation:  और अगर ये नियमों काफी नहीं हैं \n",
      "Predicted Hindi Translation:  और उन पर अधिकांश लोगों वे सच हैं \n",
      "\n",
      "\n",
      "\n",
      "Input English sentence: someday little robots will go\n",
      "Actual Hindi Translation:  एक दिन छोटे रोबोट्स हमारी धमनियों \n",
      "Predicted Hindi Translation:  एक दिन छोटे रोबोट्स में होते हैं \n",
      "\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "for _ in range(5):\n",
    "    k += 1\n",
    "    (input_seq, actual_output), _ = next(train_gen)\n",
    "    decoded_sentence = decode_sequence(input_seq)\n",
    "    print('Input English sentence:', X_train[k:k+1].values[0])\n",
    "    print('Actual Hindi Translation:', y_train[k:k+1].values[0][6:-4])\n",
    "    print('Predicted Hindi Translation:', decoded_sentence[:-4])\n",
    "    print('\\n\\n')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ddf343d9-fdae-454a-a0e7-ccf0a8a5297d",
   "metadata": {},
   "source": [
    "# Generate input sequence for new raw sentence"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "bf827c6a-c851-4560-abdd-1a41201a4b4a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_input_seq(input_str):\n",
    "    X = pd.DataFrame({'english_sentence': [input_str]})\n",
    "    X['english_sentence'] = X['english_sentence'].apply(lambda x: x.lower())\n",
    "    X['english_sentence'] = X['english_sentence'].apply(lambda x: re.sub(\"'\", '', x))\n",
    "    X['english_sentence'] = X['english_sentence'].apply(lambda x: re.sub(\"“\", '', x))\n",
    "    X['english_sentence'] = X['english_sentence'].apply(lambda x: re.sub(\"”\", '', x))\n",
    "    \n",
    "    exclude = set(string.punctuation)\n",
    "    X['english_sentence'] = X['english_sentence'].apply(lambda x: ''.join(ch for ch in x if ch not in exclude))\n",
    "    \n",
    "    remove_digits = str.maketrans('', '', digits)\n",
    "    X['english_sentence'] = X['english_sentence'].apply(lambda x: x.translate(remove_digits))\n",
    "    \n",
    "    X['english_sentence'] = X['english_sentence'].apply(lambda x: x.strip())\n",
    "    X['english_sentence'] = X['english_sentence'].apply(lambda x: re.sub(\" +\", \" \", x))\n",
    "    \n",
    "    encoder_input_data = np.zeros((1, max_length_src),dtype='float32')\n",
    "    for i, input_text in enumerate(X['english_sentence']):\n",
    "        for t, word in enumerate(input_text.split()):\n",
    "            encoder_input_data[i, t] = input_token_index[word] # encoder input seq\n",
    "\n",
    "    return encoder_input_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "efe8bc0a-9088-42cb-bec7-2dc37033b85d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def pipeline(eng_str):\n",
    "    input_seq = generate_input_seq(eng_str)\n",
    "    decoded_sentence = decode_sequence(input_seq)\n",
    "    print('Input English sentence:', eng_str)\n",
    "    print('Predicted Hindi Translation:', decoded_sentence[:-4])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "6a715e2b-aaea-473d-8f7c-3922f970fe64",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Input English sentence: I am from India\n",
      "Predicted Hindi Translation:  मैं भारत को नहीं दिया \n"
     ]
    }
   ],
   "source": [
    "pipeline(\"I am from India\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
